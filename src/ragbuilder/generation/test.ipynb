{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from ragbuilder.generation.generate_system_prompt import Generator, RAGASEvaluator\n",
    "from ragbuilder.generation.utils import dummyRetriever\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGASEvaluator initiated\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# eval_dataset_path = \"/Users/ashwinaravind/Desktop/kruxgitrepo/ragbuilder/rag_test_data_lilianweng_gpt-4o_1721032414.736622_SEMI.csv\"\n",
    "eval_dataset_path = \"/Users/ashwinaravind/Desktop/kruxgitrepo/ragbuilder/gensimtest.csv\"\n",
    "ragas_evaluator=RAGASEvaluator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from ragbuilder.generation.evaluation import RAGASEvaluator\n",
    "def sample_retriever():\n",
    "    print(\"rag_get_retriever initiated\")\n",
    "    try:\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        # LLM setup\n",
    "        llm = AzureChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # Document loader\n",
    "        loader = WebBaseLoader(\"https://raw.githubusercontent.com/ashwinaravind/ashwinaravind.github.io/refs/heads/main/thevanishingtown\")\n",
    "        docs = loader.load()\n",
    "\n",
    "        # Embedding model\n",
    "        embedding = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "        # Text splitting and embedding storage\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "        splits = splitter.split_documents(docs)\n",
    "\n",
    "        # Initialize Chroma database\n",
    "        c = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embedding,\n",
    "            collection_name=\"testindex-ragbuilder-retreiver\",\n",
    "            client_settings=chromadb.config.Settings(allow_reset=True),\n",
    "        )\n",
    "\n",
    "        # Retriever setup\n",
    "        retriever = c.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "        ensemble_retriever = EnsembleRetriever(retrievers=[retriever])\n",
    "        print(\"rag_get_retriever completed\")\n",
    "        return ensemble_retriever\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching prompts from online file: https://raw.githubusercontent.com/ashwinaravind/rag_prompts/refs/heads/main/rag_prompts.yml\n",
      "test_prompt initiated\n",
      "Testing Prompt: default_informative...\n",
      "rag_get_retriever initiated\n",
      "rag_get_retriever completed\n",
      "rag_pipeline initiated\n",
      "rag_pipeline completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd9880e6ba8471d859e0d552d6d223b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_prompt completed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af027e719fc0431d81fa4144c8d91c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_prompts completed\n",
      "Dataset({\n",
      "    features: ['prompt_key', 'prompt', 'question', 'answer', 'ground_truth', 'answer_correctness', 'faithfulness', 'answer_relevancy', 'context_precision', 'context_recall'],\n",
      "    num_rows: 1\n",
      "})\n",
      "The average correctness results have been saved to 'rag_average_correctness.csv'\n"
     ]
    }
   ],
   "source": [
    "gen=PromptGenerator(\n",
    "        eval_dataset_path=eval_dataset_path,\n",
    "        retriever=sample_retriever,\n",
    "        evaluator=ragas_evaluator,\n",
    "        prompt_template_path=None,\n",
    "        read_local=False,\n",
    "        query_rewrite=True\n",
    "        llm=llm)\n",
    "#Find the optimal prompt\n",
    "best_prompt,max_answer_correctness=gen.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Text: You are a helpful assistant. Answer any questions solely based on the context provided below. \n",
      "If the provided context does not have the relevant facts to answer the question, say \"I don't know.\"\n",
      "\n",
      "<context>\n",
      "{context}\n",
      "</context>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt Text:\", best_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_get_retriever initiated\n",
      "rag_get_retriever completed\n",
      "rag_pipeline initiated\n",
      "rag_pipeline completed\n"
     ]
    }
   ],
   "source": [
    "res=gen.setup_retrieval_qa(best_prompt,sample_retriever(),llm,query_rewrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Marek is a character who reached the edge of a clearing at night and approached a cabin that holds dark memories for him. His mother disappeared in the forest when he was a boy, and he has a connection to strange occurrences in the woods. He discovers that he and Clara, a young woman he finds in the cabin, are siblings.',\n",
       " 'context': 'Marek reached the edge of the clearing just as night began to fall. The air felt heavy with an unspoken tension. The cabin was as he remembered it—broken, abandoned, a ghost from his past. He approached cautiously, his breath steady, but his heart racing.\\n\\nAs he neared the door, it creaked slightly, as if someone had been inside. He gripped the hilt of his dagger, more out of instinct than fear. Stepping into the cabin, he saw the outline of a figure curled by the hearth.\\n\\nA young woman.\\n\\n---\\nThe cabin held dark memories for Marek. His mother had disappeared in the forest when he was only a boy. His father said she’d gone mad, claiming their family was cursed, but Marek knew better. He had seen things, even as a child—strange figures in the woods, whispers that came with the wind. And the locket. His mother always wore that locket.\\nFor a long moment, neither spoke. Then, without warning, the locket around Clara’s neck grew warm. The clasp that had been locked for years suddenly gave way, and the locket fell open.\\n\\nInside was a small, folded piece of parchment. Marek stepped closer, and together they unfolded it. The faded ink revealed two names—**Marek** and **Clara**.\\n\\nThe realization hit them both at once. “We’re…” Clara began, her voice trembling.\\n\\n“Brother and sister,” Marek finished, his voice barely a whisper.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"who is Marek?\"\n",
    "res.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [\n",
    "    \"A young woman.\",\n",
    "    \"\"\"## Chunk 3: The Locket’s Secret\n",
    "\n",
    "Clara awoke to a sound—footsteps. Her eyes shot open. In the dim light, she saw a man standing at the door, silhouetted against the night. His green eyes gleamed in the shadows.\n",
    "\n",
    "“Who are you?” she stammered, clutching her locket.\n",
    "\n",
    "“I could ask you the same,” the man replied, stepping forward. “This is my family’s cabin. What are you doing here?”\n",
    "\"\"\"\n",
    "]\n",
    "documents = dummyRetriever.strings_to_documents(strings)\n",
    "retriever = dummyRetriever(documents=documents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='## Chunk 3: The Locket’s Secret\\n\\nClara awoke to a sound—footsteps. Her eyes shot open. In the dim light, she saw a man standing at the door, silhouetted against the night. His green eyes gleamed in the shadows.\\n\\n“Who are you?” she stammered, clutching her locket.\\n\\n“I could ask you the same,” the man replied, stepping forward. “This is my family’s cabin. What are you doing here?”\\n')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Clara\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_pipeline initiated\n",
      "rag_pipeline completed\n"
     ]
    }
   ],
   "source": [
    "pipeline=gen.setup_retrieval_qa(best_prompt,retriever,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Clara is a character who awoke to the sound of footsteps and found a man with green eyes standing at the door of a cabin. She was startled and clutched her locket when she confronted him.',\n",
       " 'context': '## Chunk 3: The Locket’s Secret\\n\\nClara awoke to a sound—footsteps. Her eyes shot open. In the dim light, she saw a man standing at the door, silhouetted against the night. His green eyes gleamed in the shadows.\\n\\n“Who are you?” she stammered, clutching her locket.\\n\\n“I could ask you the same,” the man replied, stepping forward. “This is my family’s cabin. What are you doing here?”\\n'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.invoke(\"Clara\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
