{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingest Optimization Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First clone the RAGBuilder repo\n",
    "!git clone https://github.com/KruxAI/ragbuilder.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import yaml\n",
    "from ragbuilder.data_ingest.optimization import run_optimization_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_config = {\n",
    "    \"input_source\": \"sample_data.txt\",\n",
    "    \"test_dataset\": \"sample_questions.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:52:48,652 - INFO - Starting optimization process\n",
      "[I 2024-10-22 15:52:48,653] A new study created in memory with name: data_ingest_1729592534996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f779b89f0e484c815c8eceb3c0d681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:52:48,675 - INFO - Starting trial 1/10\n",
      "2024-10-22 15:52:48,676 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 300, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content='and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), 0.01955118149520163), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple\"), -0.031377721546210324)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple\"), -0.02304183355402878), (Document(metadata={'source': 'sample_data.txt'}, page_content='and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), -0.19856010824782722)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content='and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), 0.05503056715906629), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple\"), -0.08268392317549189)]\n",
      "  warnings.warn(\n",
      "2024-10-22 15:52:57,738 - INFO - Starting trial 2/10\n",
      "2024-10-22 15:52:57,738 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 100, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:52:57,737] Trial 0 finished with value: -0.04351363964488172 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 300}. Best is trial 0 with value: -0.04351363964488172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"), 0.12239100914832945), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer\"), 0.10073064788051977), (Document(metadata={'source': 'sample_data.txt'}, page_content='components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'), 0.040407886655605685), (Document(metadata={'source': 'sample_data.txt'}, page_content='document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to'), -0.008342445786278185), (Document(metadata={'source': 'sample_data.txt'}, page_content=\"pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our\"), -0.011236079817642075)]\n",
      "  warnings.warn(\n",
      "2024-10-22 15:53:00,509 - INFO - Starting trial 3/10\n",
      "2024-10-22 15:53:00,510 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 200, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:00,508] Trial 1 finished with value: 0.10513257713059354 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 100}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.\"), -0.021253205596923452)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.\"), -0.01901613517166223)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ragbuilder/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:784: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': 'sample_data.txt'}, page_content=\"# sample_data.txt This is a sample document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.\"), -0.08075342892629878)]\n",
      "  warnings.warn(\n",
      "2024-10-22 15:53:02,864 - INFO - Starting trial 4/10\n",
      "2024-10-22 15:53:02,865 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 400, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:02,864] Trial 2 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 200}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:05,556 - INFO - Starting trial 5/10\n",
      "2024-10-22 15:53:05,556 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 500, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:05,555] Trial 3 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 400}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:08,016 - INFO - Starting trial 6/10\n",
      "2024-10-22 15:53:08,017 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 100, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:08,016] Trial 4 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 500}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:10,350 - INFO - Starting trial 7/10\n",
      "2024-10-22 15:53:10,351 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 400, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:10,350] Trial 5 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 100}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:13,107 - INFO - Starting trial 8/10\n",
      "2024-10-22 15:53:13,107 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 100, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:13,106] Trial 6 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 400}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:15,341 - INFO - Starting trial 9/10\n",
      "2024-10-22 15:53:15,341 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 100, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:15,340] Trial 7 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 100}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:17,577 - INFO - Starting trial 10/10\n",
      "2024-10-22 15:53:17,578 - INFO - Trial parameters: {'input_source': 'sample_data.txt', 'test_dataset': 'sample_questions.txt', 'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_overlap': 100, 'chunk_size': 300, 'embedding_model': EmbeddingConfig(type=<EmbeddingModel.HUGGINGFACE: 'huggingface'>, model='sentence-transformers/all-MiniLM-L6-v2', model_kwargs=None, custom_class=None), 'vector_database': VectorDBConfig(type=<VectorDatabase.FAISS: 'faiss'>, collection_name=None, persist_directory=None, client_settings=None, metadata=None, custom_class=None), 'top_k': 5, 'sampling_rate': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:17,577] Trial 8 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 100}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:53:20,011 - INFO - Optimization completed. Best score: 0.1051\n",
      "2024-10-22 15:53:20,011 - INFO - Best parameters: {'chunking_strategy': <ChunkingStrategy.RECURSIVE: 'RecursiveCharacterTextSplitter'>, 'chunk_size': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-22 15:53:20,010] Trial 9 finished with value: -0.040340923231628155 and parameters: {'chunking_strategy': <ChunkingStrategy.CHARACTER: 'CharacterTextSplitter'>, 'chunk_size': 300}. Best is trial 1 with value: 0.10513257713059354.\n"
     ]
    }
   ],
   "source": [
    "best_config, best_score, best_indexer = run_optimization_from_dict(sample_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'sample_data.txt'}, page_content=\"It contains multiple sentences to demonstrate chunking. We'll use this to test our parser, chunker,\"),\n",
       "  0.12169280445589803),\n",
       " (Document(metadata={'source': 'sample_data.txt'}, page_content=\"to demonstrate chunking. We'll use this to test our parser, chunker, embedder, and indexer\"),\n",
       "  0.11005100196021889),\n",
       " (Document(metadata={'source': 'sample_data.txt'}, page_content='components. The goal is to ensure that our pipeline works end-to-end with a simple configuration.'),\n",
       "  0.04864043057523859),\n",
       " (Document(metadata={'source': 'sample_data.txt'}, page_content='document for testing the RAGBuilder data ingestion pipeline. It contains multiple sentences to'),\n",
       "  0.007918988480982936)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_indexer.similarity_search_with_relevance_scores(\"What is the purpose of this document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_overlap: 100\n",
      "chunk_size: 100\n",
      "chunking_strategy: RecursiveCharacterTextSplitter\n",
      "custom_chunker: null\n",
      "document_loader:\n",
      "  custom_class: null\n",
      "  loader_kwargs: null\n",
      "  type: !!python/object/apply:ragbuilder.data_ingest.config.ParserType\n",
      "  - unstructured\n",
      "embedding_model:\n",
      "  custom_class: null\n",
      "  model: sentence-transformers/all-MiniLM-L6-v2\n",
      "  model_kwargs: null\n",
      "  type: !!python/object/apply:ragbuilder.data_ingest.config.EmbeddingModel\n",
      "  - huggingface\n",
      "input_source: sample_data.txt\n",
      "sampling_rate: null\n",
      "test_dataset: sample_questions.txt\n",
      "top_k: 5\n",
      "vector_database:\n",
      "  client_settings: null\n",
      "  collection_name: null\n",
      "  custom_class: null\n",
      "  metadata: null\n",
      "  persist_directory: null\n",
      "  type: !!python/object/apply:ragbuilder.data_ingest.config.VectorDatabase\n",
      "  - faiss\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(best_config.model_dump()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragbuilder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
